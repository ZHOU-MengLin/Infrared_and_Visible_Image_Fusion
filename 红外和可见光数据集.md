# 红外和可见光数据集

## 一、红外和可见光图像融合数据集

| Datasets  | 下载链接                                                     |
| --------- | ------------------------------------------------------------ |
| TNO       | https://figshare.com/articles/dataset/TNO_Image_Fusion_Dataset/1008029 |
| INO       | https://www.ino.ca/en/technologies/video-analytics-dataset/videos/ |
| RoadScene | https://github.com/hanna-xu/RoadScene                        |
| MSRS      | https://github.com/Linfeng-Tang/MSRS                         |
| LLVIP     | https://bupt-ai-cz.github.io/LLVIP/                          |
| M3FD      | https://github.com/JinyuanLiu-CV/TarDAL                      |
| FMB       | https://github.com/JinyuanLiu-CV/SegMiF                      |
| M2VD      | [ M2VD：Multi-modal Multi-scene Video Dataset](https://github.com/Linfeng-Tang/M2VD) |
|           |                                                              |



Annotation: vbb format->xml format.[Link to download](https://github.com/SoonminHwang/rgbt-ped-detection/tree/master/data/scripts)

- [KAIST dataset](https://soonminhwang.github.io/rgbt-ped-detection/): The KAIST Multispectral Pedestrian Dataset consists of 95k color-thermal pairs (640x480, 20Hz) taken from a vehicle. All the pairs are manually annotated (person, people, cyclist) for the total of 103,128 dense annotations and 1,182 unique pedestrians. The annotation includes temporal correspondence between bounding boxes like Caltech Pedestrian Dataset.
  KAIST 多光谱行人数据集由取自车辆的 95k 色热对（640x480,20Hz）组成。所有对（人、人、骑自行车者）都经过手动注释，总共有 103,128 个密集注释和 1,182 个唯一行人。注释包括边界框之间的时间对应关系，例如 Caltech Pedestrian Dataset。

   - **Improved KAIST Testing Annotations** provided by Liu et al.[Link to download](https://docs.google.com/forms/d/e/1FAIpQLSe65WXae7J_KziHK9cmX_lP_hiDXe7Dsl6uBTRL0AWGML0MZg/viewform?usp=pp_url&entry.1637202210&entry.1381600926&entry.718112205&entry.233811498) 
   - Improved KAIST Training Annotations provided by Zhang et al.[Link to download](https://github.com/luzhang16/AR-CNN) 

- [LLVIP dataset](https://bupt-ai-cz.github.io/LLVIP/): This dataset contains 30976 images, or 15488 pairs, most of which were taken at very dark scenes, and all of the images are strictly aligned in time and space. Pedestrians in the dataset are labeled. We compare the dataset with other visible-infrared datasets and evaluate the performance of some popular visual algorithms including image fusion, pedestrian detection and image-to-image translation on the dataset.

- [CVC-14 dataset](http://adas.cvc.uab.es/elektra/enigma-portfolio/cvc-14-visible-fir-day-night-pedestrian-sequence-dataset/): The CVC-14 dataset is composed by two sets of sequences. These sequences are named as the day and night sets, which refers to the moment of the day they were acquired, and Visible and FIR depending the camera that was user to recor the sequences. For training 3695 images during the day, and 3390 images during night, with around 1500 mandatory pedestrian annotated for each sequence. For testing around 700 images for both sequences with around 2000 pedestrian during day, and around 1500 pedestrian during night.
  CVC-14数据集由两组串行组成。这些串行被命名为白天和黑夜集，这是指它们被采集的那一天的时刻，以及可见和 FIR，具体取决于用户用于重新捕捉串行的摄像机。为了进行训练，白天有 3695 张图像，夜间有 3390 张图像，每个串行大约有 1500 个强制性行人注释。用于测试两个串行的约 700 张图像，白天约有 2000 名行人，夜间约有 1500 名行人。

- [FLIR dataset](https://www.flir.cn/oem/adas/adas-dataset-form/): Synced annotated thermal imagery and non-annotated RGB imagery for reference. It should to noted that the infrared and RGB images are not aligned. The FLIR dataset has 10,228 total frames and 9,214 frames with bounding boxes(28151 Person, 46692 Car, 4457 Bicycle, 240 Dog, 2228 Other Vehicle).
  同步带注释的热成像图像和非带注释的 RGB 图像以供参考。应该注意的是，红外和RGB图像没有对齐。FLIR数据集共有10,228帧和9,214帧（28151人，46692汽车，4457自行车，240狗，2228其他车辆）。

  > In the original FLIR dataset, the thermal and visible images are not aligned. So Heng Zhang et al manually aligned the visible-thermal image pairs and end up with 4128 pairs for training and 1013 pairs for validation. The aligned version dataset can be downloaded here: https://drive.google.com/file/d/1xHDMGl6HJZwtarNWkEV3T4O9X4ZQYz2Y/view (This aligned dataset was firstly mentioned in Multispectral Fusion for Object Detection with Cyclic Fuse-and-Refine Blocks, ICIP 2020, Heng Zhang et al.)
  > 在原始的FLIR数据集中，热图像和可见光图像未对齐。因此，Heng Zhang 等人手动对齐了可见光-热成像对，最终得到 4128 对用于训练和 1013 对用于验证。对齐版本数据集可在此处下载：https://drive.google.com/file/d/1xHDMGl6HJZwtarNWkEV3T4O9X4ZQYz2Y/view （该对齐数据集首次在 Multispectral Fusion for Object Detection with Cyclic Fuse-and-Refine Blocks， ICIP 2020， Heng Zhang et al.） 中提及。

- [Autonomous Vehicles dataset](https://www.mi.t.u-tokyo.ac.jp/static/projects/mil_multispectral/): A novel multispectral dataset was generated for autonomous vehicles that consists of RGB, NIR, MIR, and FIR images, which prepared 7,512 images in total (3,740 taken at daytime and 3,772 taken at nighttime)





LLVIP Dataset(RGB-T Pedestrian Detection)
-----------------------------------------

Jia X, Zhu C, Li M, et al. LLVIP: A visible-infrared paired dataset for low-light vision[C]//Proceedings of the IEEE/CVF International Conference on Computer Vision. **2021**: 3496-3504.

[bupt-ai-cz/LLVIP: LLVIP: A Visible-infrared Paired Dataset for Low-light Vision (github.com)](https://link.zhihu.com/?target=https%3A//github.com/bupt-ai-cz/LLVIP)

**适用方向：热红外和可见光行人检测**

LLVIP 数据集是在时间和空间上严格对齐的数据对。用于暗光条件下的红外和可见光的行人[检测算法](https://zhida.zhihu.com/search?q=%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95&zhida_source=entity&is_preview=1)。The wavelength: 8~14um (thermal infrared images).

采集设备为海康威视摄像头：HIKVISION DS-2TD8166BJZFY-75H2F/V2

![](https://pica.zhimg.com/v2-7295e6faa0d42fc438e161556efd479a_r.jpg)![](https://pic3.zhimg.com/v2-c5da10a7e675f45e1f7eb7764ce235e2_r.jpg)![](https://pic3.zhimg.com/v2-30807e74e80e8b02c397a6b7ea8abb54_r.jpg)

M3FD Dataset(RGB-T Object Detection)
------------------------------------

Jinyuan Liu, Xin Fan*, Zhangbo Huang, Guanyao Wu, Risheng Liu , Wei Zhong, Zhongxuan Luo,**“Target-aware Dual Adversarial Learning and a Multi-scenario Multi-Modality Benchmark to Fuse Infrared and Visible for Object Detection”**, IEEE/CVF Conference on Computer Vision and Pattern Recognition**(CVPR)**, 2022.**(Oral)**

[dlut-dimt/TarDAL: CVPR 2022 | Target-aware Dual Adversarial Learning and a Multi-scenario Multi-Modality Benchmark to Fuse Infrared and Visible for Object Detection. (github.com)](https://link.zhihu.com/?target=https%3A//github.com/dlut-dimt/TarDAL)

**适用方向：热红外和可见光图像目标检测**

**数据来源：自己做的设备拍摄**

![](https://pic1.zhimg.com/v2-1ee6d3c1f5969b363c161a0edd4d3c32_r.jpg)![](https://pic2.zhimg.com/v2-e90d61009a72b1e7478fb262915b8993_r.jpg)

DUT-VTUAV Dataset(Visble-thermal UAV Tracking)
----------------------------------------------

Zhang P, Zhao J, Wang D, et al. Visible-thermal UAV tracking: A large-scale benchmark and new baseline[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 8886-8895.

[zhang-pengyu/DUT-VTUAV: Visible-Thermal UAV Tracking: A Large-Scale Benchmark (CVPR2022) (github.com)](https://link.zhihu.com/?target=https%3A//github.com/zhang-pengyu/DUT-VTUAV)

**适用方向：Visble-thermal UAV Tracking**

一个新的数据集，用于无人机的**单目标跟踪**。基于热红外和可见光图像。

**数据来源：大疆 Zenmuse H20T camera 拍摄**

our dataset is captured by a professional UAV (DJI Matrice 300 RTK) with Zenmuse H20T camera, which can achieve stable flight in extreme conditions, such as night, [foggy](https://zhida.zhihu.com/search?q=foggy&zhida_source=entity&is_preview=1), and windy scenes. The thermal camera captures **8-14µm** and we control the flight height from 5-20m for a proper target size.

[图像获取](https://zhida.zhihu.com/search?q=%E5%9B%BE%E5%83%8F%E8%8E%B7%E5%8F%96&zhida_source=entity&is_preview=1)的设备具体见：[禅思 H20 系列 - 以简驭繁 - DJI 大疆创新](https://link.zhihu.com/?target=https%3A//www.dji.com/cn/zenmuse-h20-series)

![](https://pic4.zhimg.com/v2-2b94133ca06ac38aa09b2988fb273a25_r.jpg)

[RGB-T 追踪——【多模态融合】Visible-Thermal UAV Tracking: A Large-Scale Benchmark and New Baseline_rgbt 数据集_zz 的大穗禾的博客 - CSDN 博客](https://link.zhihu.com/?target=https%3A//blog.csdn.net/qq_42312574/article/details/126013365)

[RGB-T 追踪——【数据集基准】GTOT / RGBT210 / RGBT234 / VOT-2019-2020 / LasHeR / VTUAV_zz 的大穗禾的博客 - CSDN 博客](https://link.zhihu.com/?target=https%3A//blog.csdn.net/qq_42312574/article/details/125944796)



FLIR Dataset(RGB-T object detection)
------------------------------------

[FREE - FLIR Thermal Dataset for Algorithm Training](https://link.zhihu.com/?target=https%3A//www.flir.com/oem/adas/adas-dataset-form/)

**适用方向：热红外和可见光的联合目标检测**

10k 张可将光 - 红外图像对，**但是没有对准**，进行融合前需校正；

4 个种类：训练集上有 person: 22372 个， bicycle :3986 个， car :41260 个， dog :226 个；测试集上有 person: 5779 个， bicycle :471 个， car :5432 个， dog :14 个

RoadScene Dataset(aligned infrared and visible images)
------------------------------------------------------

[frostcza/RoadScene: Datasets: road-scene-infrared-visible-images, for feature matching, image registration, and image fusion (github.com)](https://link.zhihu.com/?target=https%3A//github.com/frostcza/RoadScene)

**适用方向：红外和可见光图像融合**

**数据来源：从 FLIR 数据集中选取出，经过精细配准得到。**

This datset has 221 aligned Vis and IR image pairs containing rich scenes such as roads, vehicles, pedestrians and so on. These images are highly representative scenes from the **FLIR video**. We preprocess the background thermal noise in the original IR images, accurately align the Vis and IR image pairs, and cut out the exact registration regions to form this dataset.

该数据集**为对齐的图片，没有语义标签**。

Freiburg Thermal Dataset(仅有数据，没有标注)
-----------------------------------

J. Vertens, J. Zürn and W. Burgard, "HeatNet: Bridging the Day-Night Domain Gap in Semantic Segmentation with Thermal Images," _2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)_, Las Vegas, NV, USA, 2020, pp. 8461-8468, doi: 10.1109/IROS45743.2020.9341192.

![](https://pic1.zhimg.com/v2-af0d0f34412e06d46a2c820f5f945666_r.jpg)[http://thermal.cs.uni-freiburg.de/](https://link.zhihu.com/?target=http%3A//thermal.cs.uni-freiburg.de/)

**数据集介绍，建议看文章：**

The **Freiburg Thermal dataset** was collected during 5 daytime and 3 nighttime data collection runs, spanning the seasons summer through winter. Overall, the dataset contains 12051 daytime and 8596 nighttime time-synchronized images using **a stereo RGB camera rig (FLIR Blackfly 23S3C)** and **a stereo thermal camera rig (FLIR ADK)** mounted on the roof of our data collection vehicle. In addition to images, **we recorded the GPS/IMU data and LiDAR point clouds.** The Freiburg Thermal dataset contains highly diverse driving scenarios including highways, densely populated urban areas, residential areas, and rural districts. We also **provide a testing set** comprising 32 daytime and 32 nighttime annotated images. Each image has pixel-wise semantic labels for 13 different object classes. Annotations are provided for the following classes:_Road, Sidewalk, Building, Curb, Fence, Pole/Signs, Vegetation, Terrain, Sky, Person/Rider, Car/Truck/Bus/Train, Bicycle/Motorcycle_, and_Background._We deliberately selected extremely challenging urban and rural scenes with many traffic participants and changing illumination conditions.



## 其他数据集

### 医学图像融合数据集

###### 1. Harvard: [http://www.med.harvard.edu/AANLIB/home.html](http://www.med.harvard.edu/AANLIB/home.html)

### 多曝光图像融合

###### 1. MEF: [https://github.com/csjcai/SICE](https://github.com/csjcai/SICE)

###### 2. MEFB: [https://github.com/xingchenzhang/MEFB](https://github.com/xingchenzhang/MEFB)

### 多聚焦图像融合

###### 1. Lytro: [https://mansournejati.ece.iut.ac.ir/content/lytro-multi-focus-dataset](https://mansournejati.ece.iut.ac.ir/content/lytro-multi-focus-dataset)

###### 2. MFI-WHU: [https://github.com/HaoZhang1018/MFI-WHU](https://github.com/HaoZhang1018/MFI-WHU)

###### 3. MFFW: [https://www.semanticscholar.org/paper/MFFW%3A-A-new-dataset-for-multi-focus-image-fusion-Xu-Wei/4c0658f338849284ee4251a69b3c323908e62b45](https://www.semanticscholar.org/paper/MFFW:-A-new-dataset-for-multi-focus-image-fusion-Xu-Wei/4c0658f338849284ee4251a69b3c323908e62b45)

### 遥感影像融合

###### 1. GaoFen: [https://directory.eoportal.org/web/eoportal/satellite-missions/g](https://directory.eoportal.org/web/eoportal/satellite-missions/g)

###### 2. WorldView: [https://worldview.earthdata.nasa.gov/](https://worldview.earthdata.nasa.gov/)

###### 3. GeoEye: [https://earth.esa.int/eogateway/missions/geoeye-1](https://earth.esa.int/eogateway/missions/geoeye-1)

###### 4. QuickBird: [https://www.satimagingcorp.com/satellite-sensors/quickbird/](https://www.satimagingcorp.com/satellite-sensors/quickbird/)